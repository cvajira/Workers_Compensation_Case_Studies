{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90acb1-0989-4c1e-a453-12ad5894219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0199b95d-cbb4-4c84-aca3-f8259859f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pandas openpyxl python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190f85e-9423-4d3f-a8fc-966e7271b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4805540-707a-429d-b9e5-c0cbe46835e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key =\"XXXXXXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b12f0-02ad-44f0-9baf-6a19b98bd8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_EXCEL_FILE1 =\"C:\\\\Users\\\\vmanathunga\\\\Documents\\\\research_ready_facts_AI.xlsx\"\n",
    "OUTPUT_EXCEL_FILE1 =\"C:\\\\Users\\\\vmanathunga\\\\Documents\\\\research_ready_facts_openai_simp_O4mini.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6de5df-9aa1-4352-a7f2-e206a806cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv # For loading API key from .env file\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Load environment variables from .env file (optional but recommended)\n",
    "load_dotenv()\n",
    "\n",
    "# 1. OpenAI API Key Setup\n",
    "openai.api_key = openai_api_key\n",
    "\n",
    "# 2. Specify the OpenAI Model\n",
    "# Use a GPT-4 model identifier (\"gpt-3.5-turbo-0125\", \"gpt-4.1-mini\",\"o4-mini\")\n",
    "#\"gpt-4.1-mini\", \"o4-mini\"\n",
    "MODEL_NAME_LIST = [\"o4-mini\"]\n",
    "\n",
    "# 3. Excel File Paths\n",
    "INPUT_EXCEL_FILE = INPUT_EXCEL_FILE1  # Your input file\n",
    "# Changed output name to reflect OpenAI usage\n",
    "OUTPUT_EXCEL_FILE = OUTPUT_EXCEL_FILE1\n",
    "\n",
    "# 4. Column Names (Adjust if different in your Excel)\n",
    "FACTS_COLUMN = 'Annonymized_Facts'\n",
    "DECISION_COLUMN = \"AI_Decision\"\n",
    "\n",
    "# 5. Time Delays (in seconds)\n",
    "# Delay AFTER processing each row (in the main loop)\n",
    "MAIN_LOOP_DELAY_SECONDS = 0\n",
    "# Delay BEFORE each API call (inside the function)\n",
    "API_CALL_DELAY_SECONDS = 1   # Adjust as needed, especially if hitting rate limits\n",
    "\n",
    "# --- Function to get decision from OpenAI ---\n",
    "def get_openai_decision(facts_text, MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Sends facts to OpenAI GPT-4 and asks for a win (1) or loss (0) decision.\n",
    "    Includes a delay before making the API call.\n",
    "\n",
    "    Args:\n",
    "        facts_text (str): The text from the 'Facts' column.\n",
    "\n",
    "    Returns:\n",
    "        int: 1 for predicted plaintiff win, 0 for predicted plaintiff loss,\n",
    "             -1 if an error occurred or decision couldn't be parsed.\n",
    "    \"\"\"\n",
    "    if not facts_text or not isinstance(facts_text, str) or len(facts_text.strip()) == 0:\n",
    "        print(\"Warning: Empty or invalid facts text provided.\")\n",
    "        return -1\n",
    "\n",
    "    # Simple Prompt\n",
    "    system_prompt = \"\"\"\n",
    "    Analyze the following legal case facts. Based solely on these facts, predict whether the plaintiff likely won or lost the case.\n",
    "    Respond ONLY with the number '1' if the plaintiff likely won.\n",
    "    Respond ONLY with the number '0' if the plaintiff likely lost.\n",
    "    Do NOT provide any explanation, commentary, or any text other than '1' or '0'.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Facts:\n",
    "    ---\n",
    "    {facts_text}\n",
    "    ---\n",
    "    Decision (1 for win, 0 for loss):\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # --- ADDED DELAY before API Call ---\n",
    "        print(f\"Waiting for {API_CALL_DELAY_SECONDS} second(s) before API call...\")\n",
    "        time.sleep(API_CALL_DELAY_SECONDS)\n",
    "        # ------------------------------------\n",
    "\n",
    "        # Call the OpenAI Chat Completions endpoint\n",
    "        print(f\"Making API call to {MODEL_NAME}...\") # Added print statement\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,\n",
    "            temperature=1,       # For deterministic results (like original Gemini config)\n",
    "            #max_tokens=5,        # Needs only 1 token ('1' or '0'), small buffer\n",
    "            #top_p=0              # Corresponds to Gemini setting (less critical with temp=0)\n",
    "            # n=1, stop=None are defaults usually suitable here\n",
    "        )\n",
    "        print(\"API call complete.\") # Added print statement\n",
    "\n",
    "        # Attempt to parse the response\n",
    "        decision_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        if decision_text == '1':\n",
    "            return 1\n",
    "        elif decision_text == '0':\n",
    "            return 0\n",
    "        else:\n",
    "            print(f\"Warning: Could not parse decision from response: '{decision_text}' for facts: '{facts_text[:100]}...'\")\n",
    "            return -1\n",
    "\n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"OpenAI API rate limit exceeded: {e}. Consider increasing API_CALL_DELAY_SECONDS.\")\n",
    "        return -1\n",
    "    except openai.AuthenticationError as e:\n",
    "         print(f\"OpenAI Authentication Error: {e}. Check your API key.\")\n",
    "         # No point in continuing if auth fails\n",
    "         exit()\n",
    "    except openai.APIError as e:\n",
    "         print(f\"OpenAI API returned an API Error: {e}\")\n",
    "         return -1\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during OpenAI API call for facts: '{facts_text[:100]}...'. Error: {e}\")\n",
    "        # Optional: Log the full error or response if debugging\n",
    "        # print(f\"Full response object (if available): {response}\")\n",
    "        return -1\n",
    "\n",
    "# --- Main Processing Logic ---\n",
    "\n",
    "print(f\"\\nReading Excel file: {INPUT_EXCEL_FILE}\")\n",
    "try:\n",
    "    df = pd.read_excel(INPUT_EXCEL_FILE)\n",
    "    print(f\"Successfully read {len(df)} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input file not found at {INPUT_EXCEL_FILE}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading Excel file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Check for input column\n",
    "if FACTS_COLUMN not in df.columns:\n",
    "    print(f\"Error: Column '{FACTS_COLUMN}' not found in the Excel file.\")\n",
    "    exit()\n",
    "\n",
    "# main function############\n",
    "\n",
    "for selected_model in MODEL_NAME_LIST:\n",
    "    print(f\"\\n===== Starting processing for Model: {selected_model} =====\")\n",
    "    for run_number in range(1, 4): # Loop 1 to 5 (inclusive)\n",
    "        # Create dynamic decision column name based on model and run number\n",
    "        # e.g., \"gpt-3.5-turbo-0125_AI_Decision1\", \"gpt-3.5-turbo-0125_AI_Decision2\", etc.\n",
    "        current_decision_column = f\"{selected_model}_AI_Decision{run_number}\"\n",
    "\n",
    "        print(f\"\\n--- Model: {selected_model}, Run: {run_number} ---\")\n",
    "        print(f\"Outputting decisions to column: {current_decision_column}\")\n",
    "\n",
    "        # Ensure the Decision column for this specific run/model exists, initialize if not\n",
    "        if current_decision_column not in df.columns:\n",
    "            print(f\"Initializing column: {current_decision_column}\")\n",
    "            df[current_decision_column] = -1 # Initialize with a placeholder\n",
    "        else:\n",
    "            print(f\"Column '{current_decision_column}' already exists. Values will be updated/overwritten for this run.\")\n",
    "\n",
    "        print(f\"\\nProcessing {len(df)} rows using OpenAI model: {selected_model} (Run {run_number})...\")\n",
    "\n",
    "        # --- Iterate and call OpenAI API for each row ---\n",
    "        total_rows = len(df)\n",
    "        for index, row in df.iterrows():\n",
    "            print(f\"\\n--- Processing row {index + 1} of {total_rows} (Model: {selected_model}, Run: {run_number}) ---\")\n",
    "            facts = str(row[FACTS_COLUMN]) if pd.notna(row[FACTS_COLUMN]) else \"\"\n",
    "\n",
    "            # Get the decision from OpenAI, passing the currently selected model\n",
    "            decision = get_openai_decision(facts, selected_model)\n",
    "\n",
    "            # Update the DataFrame in the dynamically named column\n",
    "            df.loc[index, current_decision_column] = decision\n",
    "            print(f\"Row {index + 1}: Facts processed for column '{current_decision_column}'. Predicted Decision: {decision}\")\n",
    "\n",
    "            # Optional: Delay AFTER processing each row\n",
    "            if index < total_rows - 1: # Avoid sleeping after the last row of this run\n",
    "                if MAIN_LOOP_DELAY_SECONDS > 0:\n",
    "                    print(f\"Waiting for {MAIN_LOOP_DELAY_SECONDS} second(s) before next row...\")\n",
    "                    time.sleep(MAIN_LOOP_DELAY_SECONDS)\n",
    "\n",
    "        print(f\"\\n--- Finished Run {run_number} for Model: {selected_model} ---\")\n",
    "\n",
    "        # --- MODIFIED: Save the DataFrame at the end of each inner loop (run) ---\n",
    "        print(f\"Saving results to {OUTPUT_EXCEL_FILE} after Run {run_number} for Model {selected_model}...\")\n",
    "        try:\n",
    "            df.to_excel(OUTPUT_EXCEL_FILE, index=False)\n",
    "            print(f\"Successfully saved results to: {OUTPUT_EXCEL_FILE}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results to Excel file after Run {run_number} for Model {selected_model}: {e}\")\n",
    "        # --- END OF SAVE MODIFICATION FOR INNER LOOP ---\n",
    "\n",
    "    print(f\"\\n===== Finished all runs for Model: {selected_model} =====\")\n",
    "# --- END OF MODIFIED SECTION ---\n",
    "\n",
    "print(\"\\nAll processing complete.\") # This message now indicates all models and all their runs are done.\n",
    "\n",
    "# The final save after all processing is now removed as it's done per run.\n",
    "\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed6a37-0701-429e-8aa2-4640f6c55727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
