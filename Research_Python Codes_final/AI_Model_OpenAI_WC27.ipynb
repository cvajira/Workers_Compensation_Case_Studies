{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "genOihQ_j69v"
      },
      "outputs": [],
      "source": [
        "#mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Q-MmOl8tkKrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_EXCEL_FILE1 =\"/content/drive/MyDrive/worker_comp_work/WC_Final/research_ready_issues_AI.xlsx\"\n",
        "OUTPUT_EXCEL_FILE1 =\"/content/drive/MyDrive/worker_comp_work/WC_Final/research_ready_issues_openai_COT_gpt_4.1_mini.xlsx\""
      ],
      "metadata": {
        "id": "2_uXcu-FkNyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "TXB_aUwxkUsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai pandas openpyxl python-dotenv"
      ],
      "metadata": {
        "id": "xezqkjNxlLfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "6EiIz7CMk6DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "FfitG9ADlSLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "h25QdwrXlqzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from dotenv import load_dotenv # For loading API key from .env file\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Load environment variables from .env file (optional but recommended)\n",
        "load_dotenv()\n",
        "\n",
        "# 1. OpenAI API Key Setup\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# 2. Specify the OpenAI Model\n",
        "# Use a GPT-4 model identifier (\"gpt-3.5-turbo-0125\", \"gpt-4.1-mini\",\"o4-mini\")\n",
        "#\"gpt-4.1-mini\", \"o4-mini\"\n",
        "MODEL_NAME_LIST = [\"gpt-4.1-mini\"]\n",
        "\n",
        "# 3. Excel File Paths\n",
        "INPUT_EXCEL_FILE = INPUT_EXCEL_FILE1  # Your input file\n",
        "# Changed output name to reflect OpenAI usage\n",
        "OUTPUT_EXCEL_FILE = OUTPUT_EXCEL_FILE1\n",
        "\n",
        "# 4. Column Names (Adjust if different in your Excel)\n",
        "FACTS_COLUMN = 'Annonymized_Issues'\n",
        "DECISION_COLUMN = \"AI_Decision1\"\n",
        "\n",
        "# 5. Time Delays (in seconds)\n",
        "# Delay AFTER processing each row (in the main loop)\n",
        "MAIN_LOOP_DELAY_SECONDS = 0\n",
        "# Delay BEFORE each API call (inside the function)\n",
        "API_CALL_DELAY_SECONDS = 0   # Adjust as needed, especially if hitting rate limits\n",
        "\n",
        "# --- Function to get decision from OpenAI ---\n",
        "def get_openai_decision(facts_text, MODEL_NAME):\n",
        "    \"\"\"\n",
        "    Sends facts to OpenAI GPT-4 and asks for a win (1) or loss (0) decision.\n",
        "    Includes a delay before making the API call.\n",
        "\n",
        "    Args:\n",
        "        facts_text (str): The text from the 'Facts' column.\n",
        "\n",
        "    Returns:\n",
        "        int: 1 for predicted plaintiff win, 0 for predicted plaintiff loss,\n",
        "             -1 if an error occurred or decision couldn't be parsed.\n",
        "    \"\"\"\n",
        "    if not facts_text or not isinstance(facts_text, str) or len(facts_text.strip()) == 0:\n",
        "        print(\"Warning: Empty or invalid facts text provided.\")\n",
        "        return -1\n",
        "\n",
        "    # Simple Prompt\n",
        "    system_prompt = \"\"\"\n",
        "    You are a legal expert in workers compensation claim disputes, who are reading the facts of a case. Internally, go step-by-step through each fact to determine whether the plaintiff likely won or lost, carefully considering each relevant detail and legal principle. Form your conclusion based solely on the facts presented. However, do not reveal your reasoning or any internal thoughts in your final answer.\n",
        "    Respond ONLY with the number '1' if the plaintiff likely won.\n",
        "    Respond ONLY with the number '0' if the plaintiff likely lost.\n",
        "    Do NOT provide any explanation, commentary, or any text other than '1' or '0'.\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "    Facts:\n",
        "    ---\n",
        "    {facts_text}\n",
        "    ---\n",
        "    Decision (1 for win, 0 for loss):\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # --- ADDED DELAY before API Call ---\n",
        "        print(f\"Waiting for {API_CALL_DELAY_SECONDS} second(s) before API call...\")\n",
        "        time.sleep(API_CALL_DELAY_SECONDS)\n",
        "        # ------------------------------------\n",
        "\n",
        "        # Call the OpenAI Chat Completions endpoint\n",
        "        print(f\"Making API call to {MODEL_NAME}...\") # Added print statement\n",
        "        response = openai.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=messages,\n",
        "            temperature=1       # For deterministic results (like original Gemini config)\n",
        "            #max_tokens=5,        # Needs only 1 token ('1' or '0'), small buffer\n",
        "            #top_p=0              # Corresponds to Gemini setting (less critical with temp=0)\n",
        "            # n=1, stop=None are defaults usually suitable here\n",
        "        )\n",
        "        print(\"API call complete.\") # Added print statement\n",
        "\n",
        "        # Attempt to parse the response\n",
        "        decision_text = response.choices[0].message.content.strip()\n",
        "\n",
        "        if decision_text == '1':\n",
        "            return 1\n",
        "        elif decision_text == '0':\n",
        "            return 0\n",
        "        else:\n",
        "            print(f\"Warning: Could not parse decision from response: '{decision_text}' for facts: '{facts_text[:100]}...'\")\n",
        "            return -1\n",
        "\n",
        "    except openai.RateLimitError as e:\n",
        "        print(f\"OpenAI API rate limit exceeded: {e}. Consider increasing API_CALL_DELAY_SECONDS.\")\n",
        "        return -1\n",
        "    except openai.AuthenticationError as e:\n",
        "         print(f\"OpenAI Authentication Error: {e}. Check your API key.\")\n",
        "         # No point in continuing if auth fails\n",
        "         exit()\n",
        "    except openai.APIError as e:\n",
        "         print(f\"OpenAI API returned an API Error: {e}\")\n",
        "         return -1\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during OpenAI API call for facts: '{facts_text[:100]}...'. Error: {e}\")\n",
        "        # Optional: Log the full error or response if debugging\n",
        "        # print(f\"Full response object (if available): {response}\")\n",
        "        return -1\n",
        "\n",
        "# --- Main Processing Logic ---\n",
        "\n",
        "print(f\"\\nReading Excel file: {INPUT_EXCEL_FILE}\")\n",
        "try:\n",
        "    df = pd.read_excel(INPUT_EXCEL_FILE)\n",
        "    print(f\"Successfully read {len(df)} rows.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Input file not found at {INPUT_EXCEL_FILE}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error reading Excel file: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Check for input column\n",
        "if FACTS_COLUMN not in df.columns:\n",
        "    print(f\"Error: Column '{FACTS_COLUMN}' not found in the Excel file.\")\n",
        "    exit()\n",
        "\n",
        "# main function############\n",
        "\n",
        "for selected_model in MODEL_NAME_LIST:\n",
        "    print(f\"\\n===== Starting processing for Model: {selected_model} =====\")\n",
        "    for run_number in range(1, 2): # Loop 1 to 5 (inclusive)\n",
        "        # Create dynamic decision column name based on model and run number\n",
        "        # e.g., \"gpt-3.5-turbo-0125_AI_Decision1\", \"gpt-3.5-turbo-0125_AI_Decision2\", etc.\n",
        "        current_decision_column = f\"{selected_model}_AI_Decision{run_number}\"\n",
        "\n",
        "        print(f\"\\n--- Model: {selected_model}, Run: {run_number} ---\")\n",
        "        print(f\"Outputting decisions to column: {current_decision_column}\")\n",
        "\n",
        "        # Ensure the Decision column for this specific run/model exists, initialize if not\n",
        "        if current_decision_column not in df.columns:\n",
        "            print(f\"Initializing column: {current_decision_column}\")\n",
        "            df[current_decision_column] = -1 # Initialize with a placeholder\n",
        "        else:\n",
        "            print(f\"Column '{current_decision_column}' already exists. Values will be updated/overwritten for this run.\")\n",
        "\n",
        "        print(f\"\\nProcessing {len(df)} rows using OpenAI model: {selected_model} (Run {run_number})...\")\n",
        "\n",
        "        # --- Iterate and call OpenAI API for each row ---\n",
        "        total_rows = len(df)\n",
        "        for index, row in df.iterrows():\n",
        "            print(f\"\\n--- Processing row {index + 1} of {total_rows} (Model: {selected_model}, Run: {run_number}) ---\")\n",
        "            facts = str(row[FACTS_COLUMN]) if pd.notna(row[FACTS_COLUMN]) else \"\"\n",
        "\n",
        "            # Get the decision from OpenAI, passing the currently selected model\n",
        "            decision = get_openai_decision(facts, selected_model)\n",
        "\n",
        "            # Update the DataFrame in the dynamically named column\n",
        "            df.loc[index, current_decision_column] = decision\n",
        "            print(f\"Row {index + 1}: Facts processed for column '{current_decision_column}'. Predicted Decision: {decision}\")\n",
        "\n",
        "            # Optional: Delay AFTER processing each row\n",
        "            if index < total_rows - 1: # Avoid sleeping after the last row of this run\n",
        "                if MAIN_LOOP_DELAY_SECONDS > 0:\n",
        "                    print(f\"Waiting for {MAIN_LOOP_DELAY_SECONDS} second(s) before next row...\")\n",
        "                    time.sleep(MAIN_LOOP_DELAY_SECONDS)\n",
        "\n",
        "        print(f\"\\n--- Finished Run {run_number} for Model: {selected_model} ---\")\n",
        "\n",
        "        # --- MODIFIED: Save the DataFrame at the end of each inner loop (run) ---\n",
        "        print(f\"Saving results to {OUTPUT_EXCEL_FILE} after Run {run_number} for Model {selected_model}...\")\n",
        "        try:\n",
        "            df.to_excel(OUTPUT_EXCEL_FILE, index=False)\n",
        "            print(f\"Successfully saved results to: {OUTPUT_EXCEL_FILE}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving results to Excel file after Run {run_number} for Model {selected_model}: {e}\")\n",
        "        # --- END OF SAVE MODIFICATION FOR INNER LOOP ---\n",
        "\n",
        "    print(f\"\\n===== Finished all runs for Model: {selected_model} =====\")\n",
        "# --- END OF MODIFIED SECTION ---\n",
        "\n",
        "print(\"\\nAll processing complete.\") # This message now indicates all models and all their runs are done.\n",
        "\n",
        "# The final save after all processing is now removed as it's done per run.\n",
        "\n",
        "print(\"\\nScript finished.\")"
      ],
      "metadata": {
        "id": "N24V18LATnL2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}