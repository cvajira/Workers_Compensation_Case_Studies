{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "genOihQ_j69v"
      },
      "outputs": [],
      "source": [
        "#mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Q-MmOl8tkKrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_EXCEL_FILE1 =\"/content/drive/MyDrive/worker_comp_work/WC_Final/research_ready_facts_AI_sampled.xlsx\"\n",
        "OUTPUT_EXCEL_FILE1 =\"/content/drive/MyDrive/worker_comp_work/WC_Final/research_ready_facts_AI_sampled_openai_gpt_4.1_mini.xlsx\""
      ],
      "metadata": {
        "id": "2_uXcu-FkNyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "TXB_aUwxkUsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai pandas openpyxl python-dotenv"
      ],
      "metadata": {
        "id": "xezqkjNxlLfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "6EiIz7CMk6DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "FfitG9ADlSLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "h25QdwrXlqzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import json # To parse JSON output from the model\n",
        "from dotenv import load_dotenv # For loading API key from .env file\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Load environment variables from .env file (optional but recommended)\n",
        "load_dotenv()\n",
        "\n",
        "# 1. OpenAI API Key Setup\n",
        "# Make sure you have OPENAI_API_KEY set in your .env file\n",
        "# or replace os.getenv(\"OPENAI_API_KEY\") with your actual key in quotes.\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# 2. Specify the OpenAI Model\n",
        "# Note: \"gpt-4.1-mini\" and \"o4-mini\" are not standard OpenAI model names.\n",
        "# I'll use \"gpt-4o\" as a capable model for extraction.\n",
        "MODEL_NAME_LIST = [\"gpt-4.1-mini\"] # Changed to a commonly available model\n",
        "\n",
        "# 3. Excel File Paths\n",
        "INPUT_EXCEL_FILE = INPUT_EXCEL_FILE1 # Your input file\n",
        "# Changed output name to reflect the new prediction task\n",
        "OUTPUT_EXCEL_FILE = OUTPUT_EXCEL_FILE1\n",
        "\n",
        "# 4. Column Names (Adjust if different in your Excel)\n",
        "FACTS_COLUMN = 'Annonymized_Facts'\n",
        "\n",
        "# 5. Time Delays (in seconds)\n",
        "# Delay AFTER processing each row (in the main loop)\n",
        "MAIN_LOOP_DELAY_SECONDS = 0\n",
        "# Delay BEFORE each API call (inside the function)\n",
        "API_CALL_DELAY_SECONDS = 0  # Increased slightly for robustness\n",
        "\n",
        "# --- Function to get predictions from OpenAI ---\n",
        "def get_openai_predictions(facts_text, MODEL_NAME):\n",
        "    \"\"\"\n",
        "    Sends anonymized facts to OpenAI and asks it to predict Case ID, Year,\n",
        "    Plaintiff Name, and Defendant Name.\n",
        "\n",
        "    Args:\n",
        "        facts_text (str): The text from the 'Annonymized_Facts' column.\n",
        "        MODEL_NAME (str): The OpenAI model to use for the prediction.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with predicted 'Case ID', 'Year', 'Plaintiff Name',\n",
        "              'Defendant Name'. Returns None or default values if an error occurred.\n",
        "    \"\"\"\n",
        "    if not facts_text or not isinstance(facts_text, str) or len(facts_text.strip()) == 0:\n",
        "        print(\"Warning: Empty or invalid facts text provided. Returning default predictions.\")\n",
        "        return {\n",
        "            \"Predicted_ID\": \"N/A\",\n",
        "            \"Predicted_Year\": \"N/A\",\n",
        "            \"Predicted_Plaintiff\": \"N/A\",\n",
        "            \"Predicted_Defendent\": \"N/A\"\n",
        "        }\n",
        "\n",
        "    # New prompt to extract specific entities\n",
        "    system_prompt = \"\"\"\n",
        "    You are an expert at extracting case information from legal summaries. Based solely on your internal training data and knowledge (no web search), identify the following for each anonymized workers' compensation case:\n",
        "    \"Case_ID\": (string, predicted Case ID, or \"Unknown\" if not found)\n",
        "    \"Year\": (string, predicted Year the case was heard, or \"Unknown\" if not found)\n",
        "    \"Plaintiff_Name\": (string, predicted Plaintiff's Name, or \"Unknown\" if not found)\n",
        "    \"Defendant_Name\": (string, predicted Defendant's Name, or \"Unknown\" if not found)\n",
        "\n",
        "    If a piece of information is explicitly stated as anonymized or cannot be confidently extracted, use \"Unknown\" for that specific key.\n",
        "    Do NOT include any other text or explanation in your response, only the JSON object.\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "    You are given the following anonymized workers compensation case. Now predict Case ID, Year of this Case heard, Plaintiff Name and Defendant Name.\n",
        "\n",
        "    Anonymized Case Facts:\n",
        "    ---\n",
        "    {facts_text}\n",
        "    ---\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    predicted_values = {\n",
        "        \"Predicted_ID\": \"Error\",\n",
        "        \"Predicted_Year\": \"Error\",\n",
        "        \"Predicted_Plaintiff\": \"Error\",\n",
        "        \"Predicted_Defendent\": \"Error\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        print(f\"Waiting for {API_CALL_DELAY_SECONDS} second(s) before API call...\")\n",
        "        time.sleep(API_CALL_DELAY_SECONDS)\n",
        "\n",
        "        print(f\"Making API call to {MODEL_NAME} for extraction...\")\n",
        "        response = openai.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=messages,\n",
        "            temperature=1, # Use 0 for deterministic extraction\n",
        "            response_format={\"type\": \"json_object\"} # Instructs model to return JSON\n",
        "        )\n",
        "        print(\"API call complete.\")\n",
        "\n",
        "        response_content = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Attempt to parse the JSON response\n",
        "        try:\n",
        "            parsed_json = json.loads(response_content)\n",
        "            predicted_values[\"Predicted_ID\"] = parsed_json.get(\"Case_ID\", \"Unknown\")\n",
        "            predicted_values[\"Predicted_Year\"] = parsed_json.get(\"Year\", \"Unknown\")\n",
        "            predicted_values[\"Predicted_Plaintiff\"] = parsed_json.get(\"Plaintiff_Name\", \"Unknown\")\n",
        "            predicted_values[\"Predicted_Defendent\"] = parsed_json.get(\"Defendant_Name\", \"Unknown\")\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Warning: Could not parse JSON from response: '{response_content}' for facts: '{facts_text[:100]}...'\")\n",
        "            # If JSON parsing fails, keep \"Error\" or set to \"Parsing Error\"\n",
        "            predicted_values[\"Predicted_ID\"] = \"Parsing Error\"\n",
        "            predicted_values[\"Predicted_Year\"] = \"Parsing Error\"\n",
        "            predicted_values[\"Predicted_Plaintiff\"] = \"Parsing Error\"\n",
        "            predicted_values[\"Predicted_Defendent\"] = \"Parsing Error\"\n",
        "\n",
        "    except openai.RateLimitError as e:\n",
        "        print(f\"OpenAI API rate limit exceeded: {e}. Consider increasing API_CALL_DELAY_SECONDS.\")\n",
        "        # Propagate error state\n",
        "    except openai.AuthenticationError as e:\n",
        "        print(f\"OpenAI Authentication Error: {e}. Check your API key.\")\n",
        "        exit() # No point in continuing if auth fails\n",
        "    except openai.APIError as e:\n",
        "        print(f\"OpenAI API returned an API Error: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during OpenAI API call for facts: '{facts_text[:100]}...'. Error: {e}\")\n",
        "\n",
        "    return predicted_values\n",
        "\n",
        "# --- Main Processing Logic ---\n",
        "\n",
        "print(f\"\\nReading Excel file: {INPUT_EXCEL_FILE}\")\n",
        "try:\n",
        "    df = pd.read_excel(INPUT_EXCEL_FILE)\n",
        "    print(f\"Successfully read {len(df)} rows.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Input file not found at {INPUT_EXCEL_FILE}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error reading Excel file: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Check for input column\n",
        "if FACTS_COLUMN not in df.columns:\n",
        "    print(f\"Error: Column '{FACTS_COLUMN}' not found in the Excel file.\")\n",
        "    exit()\n",
        "\n",
        "# Initialize new prediction columns\n",
        "# We'll use the specific desired output column names directly\n",
        "output_columns = [\"Predicted_ID\", \"Predicted_Year\", \"Predicted_Plaintiff\", \"Predicted_Defendent\"]\n",
        "for col in output_columns:\n",
        "    if col not in df.columns:\n",
        "        df[col] = \"Not Processed\" # Initialize with a placeholder\n",
        "\n",
        "for selected_model in MODEL_NAME_LIST:\n",
        "    print(f\"\\n===== Starting processing for Model: {selected_model} =====\")\n",
        "    # Loop for runs is simplified since we are not doing multiple runs for win/loss\n",
        "    # If you want to run multiple times for average or error checking, keep the loop.\n",
        "    # For now, assuming one run for extraction\n",
        "    for run_number in range(1, 2): # Just one run for prediction\n",
        "        print(f\"\\n--- Model: {selected_model}, Run: {run_number} ---\")\n",
        "        print(f\"Predicting details into columns: {', '.join(output_columns)}\")\n",
        "\n",
        "        print(f\"\\nProcessing {len(df)} rows using OpenAI model: {selected_model} (Run {run_number})...\")\n",
        "\n",
        "        total_rows = len(df)\n",
        "        for index, row in df.iterrows():\n",
        "            print(f\"\\n--- Processing row {index + 1} of {total_rows} (Model: {selected_model}, Run: {run_number}) ---\")\n",
        "            facts = str(row[FACTS_COLUMN]) if pd.notna(row[FACTS_COLUMN]) else \"\"\n",
        "\n",
        "            # Get the predictions from OpenAI\n",
        "            predictions = get_openai_predictions(facts, selected_model)\n",
        "\n",
        "            # Update the DataFrame with the predicted values\n",
        "            df.loc[index, \"Predicted_ID\"] = predictions.get(\"Predicted_ID\", \"Error\")\n",
        "            df.loc[index, \"Predicted_Year\"] = predictions.get(\"Predicted_Year\", \"Error\")\n",
        "            df.loc[index, \"Predicted_Plaintiff\"] = predictions.get(\"Predicted_Plaintiff\", \"Error\")\n",
        "            df.loc[index, \"Predicted_Defendent\"] = predictions.get(\"Predicted_Defendent\", \"Error\")\n",
        "\n",
        "            print(f\"Row {index + 1}: Predicted ID: {predictions.get('Predicted_ID', 'Error')}, \"\n",
        "                  f\"Year: {predictions.get('Predicted_Year', 'Error')}, \"\n",
        "                  f\"Plaintiff: {predictions.get('Predicted_Plaintiff', 'Error')}, \"\n",
        "                  f\"Defendant: {predictions.get('Predicted_Defendent', 'Error')}\")\n",
        "\n",
        "            if index < total_rows - 1:\n",
        "                if MAIN_LOOP_DELAY_SECONDS > 0:\n",
        "                    print(f\"Waiting for {MAIN_LOOP_DELAY_SECONDS} second(s) before next row...\")\n",
        "                    time.sleep(MAIN_LOOP_DELAY_SECONDS)\n",
        "\n",
        "        print(f\"\\n--- Finished Run {run_number} for Model: {selected_model} ---\")\n",
        "\n",
        "        # Save the DataFrame after each run (or after all runs if not looping)\n",
        "        print(f\"Saving results to {OUTPUT_EXCEL_FILE}...\")\n",
        "        try:\n",
        "            df.to_excel(OUTPUT_EXCEL_FILE, index=False)\n",
        "            print(f\"Successfully saved results to: {OUTPUT_EXCEL_FILE}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving results to Excel file: {e}\")\n",
        "\n",
        "    print(f\"\\n===== Finished all runs for Model: {selected_model} =====\")\n",
        "\n",
        "print(\"\\nAll processing complete. Script finished.\")"
      ],
      "metadata": {
        "id": "N24V18LATnL2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}