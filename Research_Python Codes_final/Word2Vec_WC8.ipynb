{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Using Word2Vec embedding approach and RF, GB, and XGB to classify Decision according to Facts"
      ],
      "metadata": {
        "id": "_ZPHSejP4Oig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ETiatDyM5EBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "451EddMf9uEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiesZb2X34mC"
      },
      "outputs": [],
      "source": [
        "INPUT_EXCEL_FILE3 = \"/content/drive/MyDrive/worker_comp_work/WC_Final/research_ready_Facts_train.xlsx\"\n",
        "INPUT_EXCEL_FILE4 = \"/content/drive/MyDrive/worker_comp_work/WC_Final/research_ready_Facts_test.xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load training and testing files for Issues\n",
        "df_train_facts = pd.read_excel(INPUT_EXCEL_FILE3)\n",
        "df_test_facts = pd.read_excel(INPUT_EXCEL_FILE4)"
      ],
      "metadata": {
        "id": "PN1iWITW5R2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_facts.columns"
      ],
      "metadata": {
        "id": "H8DoQILP5dRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_facts.shape\n",
        "#should be 4882"
      ],
      "metadata": {
        "id": "CJtQMX_-5iuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_facts.shape\n",
        "#should be 1221"
      ],
      "metadata": {
        "id": "LCU7SfHg5m9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check unique values in 'Decision' column\n",
        "df_train_facts['Decision'].unique()"
      ],
      "metadata": {
        "id": "X8gi7Oyg5tAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the distribution of Decsion variable in train and test as percentage\n",
        "df_train_facts['Decision'].value_counts(normalize=True)\n",
        "#should be about 64.4%-35.5%"
      ],
      "metadata": {
        "id": "62b08Ayj52jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_facts['Decision'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "Kp9G-OQW7Sfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = df_train_facts['Preprocessed_Facts'].tolist()\n",
        "test_text = df_test_facts['Preprocessed_Facts'].tolist()\n",
        "\n",
        "train_labels = df_train_facts['Decision'].tolist()\n",
        "test_labels = df_test_facts['Decision'].tolist()"
      ],
      "metadata": {
        "id": "A3L1AEca7eq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install \"numpy<2.0\"  # or try \"numpy==1.26.4\"\n",
        "#!pip install gensim"
      ],
      "metadata": {
        "id": "9-Gicj6qRoU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.preprocessing import scale\n",
        "import nltk\n",
        "nltk.download('punkt')  # Download tokenizer models\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "dWGIsDYc8BY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "3khsny3TSz_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "yFnAVQnaTHAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization function\n",
        "def tokenize_text(texts):\n",
        "    \"\"\"\n",
        "    Tokenize a list of sentences into words.\n",
        "\n",
        "    Parameters:\n",
        "    - texts: List of raw sentences (strings)\n",
        "\n",
        "    Returns:\n",
        "    - List of tokenized sentences (lists of words)\n",
        "    \"\"\"\n",
        "    return [word_tokenize(text.lower()) for text in texts]  # Lowercase and tokenize\n",
        "\n",
        "# Word2Vec training function\n",
        "def train_word2vec(sentences, embedding_dim=100, min_word_count=1, context=5):\n",
        "    \"\"\"\n",
        "    Train a Word2Vec model on the given text data.\n",
        "\n",
        "    Parameters:\n",
        "    - sentences: List of tokenized sentences\n",
        "    - embedding_dim: Dimensionality of word vectors\n",
        "    - min_word_count: Minimum word count to include in the model\n",
        "    - context: Context window size\n",
        "\n",
        "    Returns:\n",
        "    - Trained Word2Vec model\n",
        "    \"\"\"\n",
        "    # Initialize and train the Word2Vec model\n",
        "    model = Word2Vec(sentences, vector_size=embedding_dim, window=context, min_count=min_word_count, workers=4)\n",
        "    return model\n",
        "\n",
        "# Function to average word embeddings for a sentence\n",
        "def get_average_word2vec(words, model, embedding_dim):\n",
        "    \"\"\"\n",
        "    Average the Word2Vec vectors for a list of words.\n",
        "\n",
        "    Parameters:\n",
        "    - words: List of words in a sentence/document\n",
        "    - model: Trained Word2Vec model\n",
        "    - embedding_dim: Dimension of Word2Vec embeddings\n",
        "\n",
        "    Returns:\n",
        "    - Averaged Word2Vec feature vector for the sentence/document\n",
        "    \"\"\"\n",
        "    # Initialize a zero vector\n",
        "    feature_vec = np.zeros((embedding_dim,), dtype=\"float32\")\n",
        "    num_words = 0\n",
        "\n",
        "    for word in words:\n",
        "        if word in model.wv:\n",
        "            num_words += 1\n",
        "            feature_vec = np.add(feature_vec, model.wv[word])\n",
        "\n",
        "    if num_words > 0:\n",
        "        feature_vec = np.divide(feature_vec, num_words)\n",
        "\n",
        "    return feature_vec\n",
        "\n",
        "# Main function to tokenize and convert text data to Word2Vec features\n",
        "def loadDataWord2Vec(X_train, X_test, embedding_dim=100, context=5):\n",
        "    \"\"\"\n",
        "    Convert the training and test data into Word2Vec-based numerical features.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train: List of raw training sentences\n",
        "    - X_test: List of raw test sentences\n",
        "    - embedding_dim: Dimensionality of word embeddings\n",
        "    - context: Context window size for Word2Vec\n",
        "\n",
        "    Returns:\n",
        "    - X_train_w2v: Word2Vec-based numerical features for training data\n",
        "    - X_test_w2v: Word2Vec-based numerical features for test data\n",
        "    \"\"\"\n",
        "    # Step 1: Tokenize the raw sentences\n",
        "    X_train_tokenized = tokenize_text(X_train)\n",
        "    X_test_tokenized = tokenize_text(X_test)\n",
        "\n",
        "    # Step 2: Train Word2Vec model on the tokenized sentences\n",
        "    sentences = X_train_tokenized + X_test_tokenized  # Combine train and test data for Word2Vec training\n",
        "    word2vec_model = train_word2vec(sentences, embedding_dim=embedding_dim, context=context)\n",
        "\n",
        "    # Step 3: Convert each tokenized sentence into a numerical feature vector\n",
        "    X_train_w2v = np.array([get_average_word2vec(sentence, word2vec_model, embedding_dim) for sentence in X_train_tokenized])\n",
        "    X_test_w2v = np.array([get_average_word2vec(sentence, word2vec_model, embedding_dim) for sentence in X_test_tokenized])\n",
        "\n",
        "    print(f\"Word2Vec with {embedding_dim} features\")\n",
        "    return X_train_w2v, X_test_w2v"
      ],
      "metadata": {
        "id": "yQh_Tskaup4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numerical features using TF-IDF\n",
        "X_train_w2v, X_test_w2v = loadDataWord2Vec(train_text, test_text, embedding_dim=100)"
      ],
      "metadata": {
        "id": "OIKmv7Kg8X-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_w2v[0]"
      ],
      "metadata": {
        "id": "WDC-uSsp8yn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train_w2v)"
      ],
      "metadata": {
        "id": "jVD0yf9x82-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=train_labels\n",
        "y_test=test_labels"
      ],
      "metadata": {
        "id": "OEl_Q2t_9Yy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.metrics import specificity_score\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    recall_score,\n",
        "    precision_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        ")\n"
      ],
      "metadata": {
        "id": "iSbGORIR9AOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a code for calculating model performance metrics and deliver it as one single data frame\n",
        "def model_metrics(model, predictors, targets):\n",
        "  pred=model.predict(predictors)\n",
        "  pred_prob=model.predict_proba(predictors)[:,1]\n",
        "\n",
        "  acc=accuracy_score(targets, pred)\n",
        "  rec=recall_score(targets, pred)\n",
        "  spec=specificity_score(targets, pred, average='binary')\n",
        "  prec=precision_score(targets, pred)\n",
        "  f1=f1_score(targets, pred)\n",
        "  auc=roc_auc_score(targets,pred_prob)\n",
        "\n",
        "  df_metrics=pd.DataFrame({}, index=['Metrics'])\n",
        "  df_metrics['Accuracy']=acc\n",
        "  df_metrics['Recall']=rec\n",
        "  df_metrics['Specificity']=spec\n",
        "  df_metrics['Precision']=prec\n",
        "  df_metrics['F1']=f1\n",
        "  df_metrics['AUC']=auc\n",
        "\n",
        "  return df_metrics"
      ],
      "metadata": {
        "id": "V85TEBYc9Ijj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and Display confusion matrix\n",
        "\n",
        "def display_confusion_matrix(model, predictors, targets):\n",
        "  pred=model.predict(predictors)\n",
        "  cm=confusion_matrix(targets, pred)\n",
        "  #cm_percentage=cm.astype('float')/cm.sum()*100\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion Matrix\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "IMYIBlBB9LTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Random Forest Classifier"
      ],
      "metadata": {
        "id": "n0LFGs2B-kfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Initialize the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Step 2: Train the model using X_train_w2v and y_train\n",
        "rf_classifier.fit(X_train_w2v, y_train)\n",
        "\n",
        "# Step 3: Make predictions on the test set\n",
        "test_performance=model_metrics(rf_classifier, X_test_w2v, y_test)\n",
        "test_performance"
      ],
      "metadata": {
        "id": "vlNarfEg9OTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_confusion_matrix(rf_classifier, X_test_w2v, y_test)"
      ],
      "metadata": {
        "id": "t01le_iY9iHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune the model\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "# defining model\n",
        "Model =RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "\n",
        "# Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50,110,25],\n",
        "    \"min_samples_leaf\": np.arange(1, 4),\n",
        "    \"max_features\": [0.3, 0.4, 0.5, 'sqrt'],\n",
        "    \"max_samples\": np.arange(0.4, 0.7, 0.1)\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(metrics.recall_score)\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv_RF = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=10, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv_RF.fit(X_train_w2v, y_train)\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv_RF.best_params_,randomized_cv_RF.best_score_))"
      ],
      "metadata": {
        "id": "I7sCHf-6jRXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params=randomized_cv_RF.best_params_\n",
        "tuned_RF=RandomForestClassifier(random_state=42, class_weight='balanced', **best_params)\n",
        "tuned_RF.fit(X_train_w2v, y_train)"
      ],
      "metadata": {
        "id": "RvQkd2azVsrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_performance_tunedRF=model_metrics(tuned_RF, X_test_w2v, y_test)\n",
        "test_performance_tunedRF.round(4)"
      ],
      "metadata": {
        "id": "pox6ZSW5Vzr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "Q1TFDOs0-qcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Initialize the Gradient Boosting Classifier\n",
        "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Step 2: Train the model using X_train_w2v and y_train\n",
        "gb_classifier.fit(X_train_w2v, y_train)\n",
        "\n",
        "\n",
        "# Step 3: Make predictions on the test set\n",
        "test_performance=model_metrics(gb_classifier, X_test_w2v, y_test)\n",
        "test_performance"
      ],
      "metadata": {
        "id": "PKB83MOa-aR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_confusion_matrix(gb_classifier, X_test_w2v, y_test)"
      ],
      "metadata": {
        "id": "-krvbD7D-4DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nBW5J_ogWNNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining model\n",
        "\n",
        "# To help with model building\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    AdaBoostClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    RandomForestClassifier,\n",
        "    BaggingClassifier,\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "Model =GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Parameter grid to pass in RandomSearchCV\n",
        "param_grid = {\n",
        "    \"n_estimators\": np.arange(50,110,25),\n",
        "    \"learning_rate\": [0.01,0.1,0.05],\n",
        "    \"subsample\":[0.7,0.9],\n",
        "    \"max_features\":[0.5,0.7,1],\n",
        "    \"max_depth\":[3,4,5],\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(metrics.recall_score)\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv_GB = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=10, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv_GB.fit(X_train_w2v, y_train)\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv_GB.best_params_,randomized_cv_GB.best_score_))"
      ],
      "metadata": {
        "id": "aLOFcSrHmIQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params=randomized_cv_GB.best_params_\n",
        "tuned_GB=GradientBoostingClassifier(random_state=42,  **best_params)\n",
        "tuned_GB.fit(X_train_w2v, y_train)"
      ],
      "metadata": {
        "id": "gjEehfFMXEL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_performance_tunedGB=model_metrics(tuned_GB, X_test_w2v, y_test)\n",
        "test_performance_tunedGB.round(4)"
      ],
      "metadata": {
        "id": "6W_DIbPWXJIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using XGBoost classifier"
      ],
      "metadata": {
        "id": "9HFAD_iK_gfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "o-dMLo6A_l00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Initialize the XGBoost Classifier\n",
        "xgb_classifier = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Step 2: Train the model using X_train_w2v and y_train\n",
        "xgb_classifier.fit(X_train_w2v, y_train)\n",
        "\n",
        "# Step 3: Make predictions on the test set\n",
        "test_performance=model_metrics(xgb_classifier, X_test_w2v, y_test)\n",
        "test_performance\n"
      ],
      "metadata": {
        "id": "YdFzLidV_ozY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# defining model\n",
        "Model = XGBClassifier(random_state=42)\n",
        "\n",
        "# Parameter grid to pass in RandomSearchCV\n",
        "param_grid={'n_estimators':np.arange(50,110,25),\n",
        "            'scale_pos_weight':[1,2,5],\n",
        "            'learning_rate':[0.01,0.1,0.05],\n",
        "            'gamma':[1,3],\n",
        "            'subsample':[0.7,0.9]\n",
        "}\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "scorer = metrics.make_scorer(metrics.recall_score)\n",
        "\n",
        "#Calling RandomizedSearchCV\n",
        "randomized_cv_XGB = RandomizedSearchCV(estimator=Model, param_distributions=param_grid, n_iter=10, n_jobs = -1, scoring=scorer, cv=5, random_state=1)\n",
        "\n",
        "#Fitting parameters in RandomizedSearchCV\n",
        "randomized_cv_XGB.fit(X_train_w2v, y_train)\n",
        "\n",
        "print(\"Best parameters are {} with CV score={}:\" .format(randomized_cv_XGB.best_params_,randomized_cv_XGB.best_score_))"
      ],
      "metadata": {
        "id": "nm2PnJ_MXct4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params=randomized_cv_XGB.best_params_\n",
        "tuned_XGB=XGBClassifier(random_state=42,  **best_params)\n",
        "tuned_XGB.fit(X_train_w2v, y_train)"
      ],
      "metadata": {
        "id": "cVs2XYGMYBPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_performance_tunedXGB=model_metrics(tuned_XGB, X_test_w2v, y_test)\n",
        "test_performance_tunedXGB.round(4)"
      ],
      "metadata": {
        "id": "iEd7cJbUYFGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost- Using Oversampling/Undersampling Approach"
      ],
      "metadata": {
        "id": "It7DmBXgAOwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To oversample and undersample data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "metadata": {
        "id": "Zo6X5HjoAR2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before Oversampling, counts of label '1': {}\".format(sum(y_train)))\n",
        "print(\"Before Oversampling, counts of label '0': {} \\n\".format(len(y_train)-sum(y_train)))"
      ],
      "metadata": {
        "id": "wIW2ST-HAUKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For oversampling\n",
        "sm = SMOTE(\n",
        "    sampling_strategy=1, k_neighbors=5, random_state=1\n",
        ")  # Synthetic Minority Over Sampling Technique\n",
        "X_train_over, y_train_over = sm.fit_resample(\n",
        "  X_train_w2v, y_train)"
      ],
      "metadata": {
        "id": "N4__Xl08AXAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for undersampling\n",
        "\n",
        "rus = RandomUnderSampler(random_state=1)\n",
        "X_train_un, y_train_un = rus.fit_resample(X_train_w2v, y_train)"
      ],
      "metadata": {
        "id": "F9pxesg8Aaed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"After Oversampling, counts of label '1': {}\".format(sum(y_train_over)))\n",
        "print(\"After Oversampling, counts of label '0': {} \\n\".format(len(y_train_over)-sum(y_train_over)))"
      ],
      "metadata": {
        "id": "_t56Cpz5AdfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"After undersampling, counts of label '1': {}\".format(sum(y_train_un)))\n",
        "print(\"After undersampling, counts of label '0': {} \\n\".format(len(y_train_un)-sum(y_train_un)))"
      ],
      "metadata": {
        "id": "JXVGnKn4Ag1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversampling and XGB\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Initialize the XGBoost Classifier\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42,  **best_params)\n",
        "\n",
        "# Step 2: Train the model using X_train_w2v and y_train\n",
        "xgb_classifier.fit(X_train_over, y_train_over)\n",
        "\n",
        "# Step 3: Make predictions on the test set\n",
        "test_performance_xgbover=model_metrics(xgb_classifier, X_test_w2v, y_test)\n",
        "test_performance_xgbover.round(4)"
      ],
      "metadata": {
        "id": "nqThbnsHAkyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersampling and XGB\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Initialize the XGBoost Classifier\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42,  **best_params)\n",
        "\n",
        "# Step 2: Train the model using X_train_w2v and y_train\n",
        "xgb_classifier.fit(X_train_un, y_train_un)\n",
        "\n",
        "# Step 3: Make predictions on the test set\n",
        "test_performance_xgbunder=model_metrics(xgb_classifier, X_test_w2v, y_test)\n",
        "test_performance_xgbunder.round(4)"
      ],
      "metadata": {
        "id": "mH0ltJmXAp9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_performance_tunedRF.round(4))\n",
        "print(test_performance_tunedGB.round(4))\n",
        "print(test_performance_tunedXGB.round(4))\n",
        "print(test_performance_xgbover.round(4))\n",
        "print(test_performance_xgbunder.round(4))"
      ],
      "metadata": {
        "id": "xnEC3CWGk8qm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}